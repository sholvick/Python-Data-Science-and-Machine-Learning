{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting /tmp/data\\train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting /tmp/data\\train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting /tmp/data\\t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting /tmp/data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# import the data - hand-written data set\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "# import the data\n",
    "\n",
    "mnist = input_data.read_data_sets(\"/tmp/data\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.contrib.learn.python.learn.datasets.base.Datasets"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data consists of hand-written digits 0 thru 9, which we will use to try to determine the digit\n",
    "\n",
    "type(mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.]], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.contrib.learn.python.learn.datasets.base.Datasets"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 784)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.02352941,  0.76470596,\n",
       "        0.99607849,  1.        ,  0.93725497,  0.1137255 ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.02352941,  0.63921571,  0.99607849,  0.99607849,  0.68627453,\n",
       "        0.21568629,  0.01176471,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.09019608,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.47450984,  0.99607849,\n",
       "        0.99607849,  0.58039218,  0.03137255,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.54901963,  0.92941183,\n",
       "        0.43921572,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.16862746,  0.96078438,  0.99607849,  0.94901967,  0.01568628,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.20784315,  0.92549026,  0.99607849,  0.43921572,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.64313728,  0.99607849,\n",
       "        0.98039222,  0.25098041,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.66274512,  0.99607849,\n",
       "        0.97647065,  0.1254902 ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.83921576,  0.99607849,  0.69803923,  0.        ,\n",
       "        0.        ,  0.01176471,  0.03529412,  0.03529412,  0.03529412,\n",
       "        0.17254902,  0.90980399,  0.99607849,  0.64705884,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.83921576,\n",
       "        0.99607849,  0.72549021,  0.        ,  0.21176472,  0.72941178,\n",
       "        0.99607849,  0.99607849,  0.99607849,  0.99607849,  0.99607849,\n",
       "        0.90588242,  0.16862746,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.37647063,  0.99607849,  0.98039222,\n",
       "        0.74509805,  0.98823535,  0.99607849,  0.99607849,  0.99607849,\n",
       "        0.99607849,  0.99607849,  0.99607849,  0.50980395,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.49411768,  0.99607849,  0.99607849,  0.99607849,  0.99607849,\n",
       "        0.78039223,  0.46274513,  0.56862748,  0.99607849,  0.99607849,\n",
       "        0.99607849,  0.30588236,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.10980393,  0.47058827,\n",
       "        0.47058827,  0.47058827,  0.1254902 ,  0.01176471,  0.        ,\n",
       "        0.47450984,  0.99607849,  0.99607849,  0.76470596,  0.01568628,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.43137258,  0.99607849,\n",
       "        0.99607849,  0.33333334,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.41960788,  0.99607849,  0.98823535,  0.19215688,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.82352948,\n",
       "        0.99607849,  0.71764708,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.05882353,  0.87843144,  0.99607849,  0.27843139,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.27058825,\n",
       "        0.99607849,  0.97647065,  0.20784315,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.84705889,  0.99607849,  0.92549026,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.87450987,  0.99607849,  0.74509805,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.87450987,  0.99607849,\n",
       "        0.73333335,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.87450987,  0.99607849,  0.97647065,  0.49411768,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.44705886,\n",
       "        0.9333334 ,  0.99607849,  0.48627454,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at one of the images in the dataset\n",
    "\n",
    "mnist.train.images[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.images[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.02352941,  0.76470596,  0.99607849,  1.        ,  0.93725497,\n",
       "         0.1137255 ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.02352941,\n",
       "         0.63921571,  0.99607849,  0.99607849,  0.68627453,  0.21568629,\n",
       "         0.01176471,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.09019608,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.47450984,\n",
       "         0.99607849,  0.99607849,  0.58039218,  0.03137255,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.54901963,\n",
       "         0.92941183,  0.43921572,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.16862746,  0.96078438,\n",
       "         0.99607849,  0.94901967,  0.01568628,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.20784315,  0.92549026,\n",
       "         0.99607849,  0.43921572,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.64313728,  0.99607849,\n",
       "         0.98039222,  0.25098041,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.66274512,  0.99607849,\n",
       "         0.97647065,  0.1254902 ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.83921576,  0.99607849,\n",
       "         0.69803923,  0.        ,  0.        ,  0.01176471,  0.03529412,\n",
       "         0.03529412,  0.03529412,  0.17254902,  0.90980399,  0.99607849,\n",
       "         0.64705884,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.83921576,  0.99607849,\n",
       "         0.72549021,  0.        ,  0.21176472,  0.72941178,  0.99607849,\n",
       "         0.99607849,  0.99607849,  0.99607849,  0.99607849,  0.90588242,\n",
       "         0.16862746,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.37647063,  0.99607849,\n",
       "         0.98039222,  0.74509805,  0.98823535,  0.99607849,  0.99607849,\n",
       "         0.99607849,  0.99607849,  0.99607849,  0.99607849,  0.50980395,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.49411768,  0.99607849,\n",
       "         0.99607849,  0.99607849,  0.99607849,  0.78039223,  0.46274513,\n",
       "         0.56862748,  0.99607849,  0.99607849,  0.99607849,  0.30588236,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.10980393,  0.47058827,\n",
       "         0.47058827,  0.47058827,  0.1254902 ,  0.01176471,  0.        ,\n",
       "         0.47450984,  0.99607849,  0.99607849,  0.76470596,  0.01568628,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.43137258,  0.99607849,  0.99607849,  0.33333334,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.41960788,  0.99607849,  0.98823535,  0.19215688,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.82352948,  0.99607849,  0.71764708,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.05882353,\n",
       "         0.87843144,  0.99607849,  0.27843139,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.27058825,\n",
       "         0.99607849,  0.97647065,  0.20784315,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.84705889,\n",
       "         0.99607849,  0.92549026,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.87450987,\n",
       "         0.99607849,  0.74509805,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.87450987,\n",
       "         0.99607849,  0.73333335,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.87450987,\n",
       "         0.99607849,  0.97647065,  0.49411768,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.44705886,\n",
       "         0.9333334 ,  0.99607849,  0.48627454,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# note it is one dimensional, 784 columns\n",
    "\n",
    "# let's reshape it back to it's original square shape (which is 28 x 28 , which = 784)\n",
    "\n",
    "sample = mnist.train.images[2].reshape(28,28)\n",
    "\n",
    "mnist.train.images[2].reshape(28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "28*28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# look at the data in the re-shaped array above - mostly 0's, \n",
    "#but some numbers, which indicate the darkness for that sector of the array\n",
    "\n",
    "# now in the 28x28 form, we can visualize it in matplotlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1ec00eb16a0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCD+QFOEHkiL8QFKEH0iK8ANJEX4gqf8HAIELZI9qhowAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ec00bb5240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# simple visualization of the sample array\n",
    "\n",
    "plt.imshow(sample, cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1ec02247390>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ec021cdd68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# try some of the other items in the ~5500 samples...\n",
    "\n",
    "sample = mnist.train.images[2034].reshape(28,28)\n",
    "plt.imshow(sample, cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Next step, define some parameters\n",
    "\n",
    "# 1. learning rate : how quickly we adjust the 'cost function' (bias?)\n",
    "# 2. number of training epochs : how many training cycles we go through\n",
    "# 3. batch size : size of the batches of training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# network parameters, directly define what our neural network (multi - layer perceptron) will look like\n",
    "\n",
    "# number of classes\n",
    "n_classes = 10\n",
    "\n",
    "# number of samples (can be obtains from the sample set directly)\n",
    "n_samples = mnist.train.num_examples\n",
    "\n",
    "# number of what we expect the input to look like - original version is 784 inputs in flat array\n",
    "n_input = 784\n",
    "\n",
    "# how many neurons we want in the 2 hidden layers we will be using\n",
    "n_hidden_1 = 256    # this is related to computer 8-bit color storage\n",
    "n_hidden_2 = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Steps that we will be performing:\n",
    "\n",
    "1. Receive the input data array and send it to the first hidden layer (n_hidden_1)\n",
    "2. Data will begin to have a weight attached to it between the layers (first round is random)\n",
    "2.a add a bias to help this\n",
    "\n",
    "This will continue on to the next hidden layer until all hidden layers have been processed\n",
    "\n",
    "Note: The more layers, the longer it will take the model to run, though the more accurate the result may likely be\n",
    "\n",
    "3. Once that transformed data that has been evaluated by these weights has reached the output layer, we will need\n",
    "    to evaluate how far off we are from the desired result\n",
    "4. We will use a 'loss' or 'cost' function to measure how far off we are, how many we got correct\n",
    "5. Apply an optimization value to try to minimize the cost and adjust the 'bias' as needed\n",
    "    - we will use the Adam optimizer\n",
    "6. Once bias is asjusted, the model runs again incrementing the bias as per the learning_rate parameter\n",
    "7. All these steps continue until a sufficient accuracy is achieved in training the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "###  Part 2  ###\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# now let's create a function for the multi-layer perceptron\n",
    "# start with 2 hidden layers\n",
    "# use the 'RELU Activation function', which is a very simple rectifier function that returns x or 0, whichever is greater\n",
    "# then final output layer will use a linear activation with matrix multiplication\n",
    "\n",
    "def multilayer_perceptron(x,weights,biases):\n",
    "    '''\n",
    "    x: Placeholder for Data input\n",
    "    weights; Dict of weights\n",
    "    biases: Dict of bias values\n",
    "    '''\n",
    "    \n",
    "    # First Hidden Layer with RELU Activation \n",
    "    # X * Weight + Bias_value\n",
    "    layer_1 = tf.add(tf.matmul(x,weights['h1']), biases['b1'])\n",
    "    # Func RELU(X * W + B) --> f(x) = max(0,x)\n",
    "    layer_1 = tf.nn.relu(layer_1)\n",
    "    \n",
    "    # Second Hidden layer\n",
    "    layer_2 = tf.add(tf.matmul(layer_1,weights['h2']), biases['b2'])\n",
    "    # same RELU activation as layer_1\n",
    "    layer_2 = tf.nn.relu(layer_2)\n",
    "    \n",
    "    # Last Output Layer\n",
    "    out_layer = tf.matmul(layer_2, weights['out']) + biases['out']\n",
    "    \n",
    "    return out_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# now create the 2 dictionaries containing the Weights and Biases to be fed into the multilayer_perceptron function\n",
    "\n",
    "# tf.variable tf object\n",
    "\n",
    "# weights dict\n",
    "weights = {\n",
    "    'h1':tf.Variable(tf.random_normal([n_input, n_hidden_1])),  # create a random output from a normal distribution\n",
    "    'h2':tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\n",
    "    'out':tf.Variable(tf.random_normal([n_hidden_2, n_classes]))\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'h1': <tf.Variable 'Variable_18:0' shape=(784, 256) dtype=float32_ref>,\n",
       " 'h2': <tf.Variable 'Variable_19:0' shape=(256, 256) dtype=float32_ref>,\n",
       " 'out': <tf.Variable 'Variable_20:0' shape=(256, 10) dtype=float32_ref>}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# expect the output to look like:  [ 0 0 0 0 0 1 0 0 0 0 ]\n",
    "# which will translate to #'s:       0 1 2 3 4 5 6 7 8 9\n",
    "# this is how we determine the value from the output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# biases dict\n",
    "# this is just the values we will be adding to the weights multiplied by the data\n",
    "\n",
    "biases = {\n",
    "    'b1':tf.Variable(tf.random_normal([n_hidden_1])),  # create a random output from a normal distribution\n",
    "    'b2':tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "    'out':tf.Variable(tf.random_normal([n_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set 2 placeholders for x and y\n",
    "\n",
    "x = tf.placeholder('float', [None, n_input])\n",
    "y = tf.placeholder('float', [None, n_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the prediction model\n",
    "\n",
    "pred = multilayer_perceptron(x, weights, biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define our cost and optimization functions\n",
    "# use built-in tensor flow functions for this\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=pred))\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "###  Part 3  ###\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        ..., \n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.]], dtype=float32),\n",
       " array([[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.],\n",
       "        [ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.],\n",
       "        [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]]))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train our model for the specified number of epochs (15)\n",
    "\n",
    "# convenience method to create batches - we will feed in our batch_size variable from above, with is 100,\n",
    "#  so model will take batchs of 100 each time\n",
    "\n",
    "mnist.train.next_batch(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = mnist.train.next_batch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xsamp, ysamp = t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1ec02bed908>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngaAIPxDUfwCCqjr+ZFHz4wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ec0288d048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(Xsamp.reshape(28,28), cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ysamp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# launch an interactive session (not as we did before with 'with Session() as sess....)\n",
    "# this way we can interact with it without having to define everying at once under the 'with' line\n",
    "\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-63-49f0ea653325>:3: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    }
   ],
   "source": [
    "# initialize all the variables we will be using\n",
    "\n",
    "init = tf.initialize_all_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1  cost146.9307\n",
      "Epoch : 2  cost37.8179\n",
      "Epoch : 3  cost24.0059\n",
      "Epoch : 4  cost16.7414\n",
      "Epoch : 5  cost12.1170\n",
      "Epoch : 6  cost9.0064\n",
      "Epoch : 7  cost6.6328\n",
      "Epoch : 8  cost4.8331\n",
      "Epoch : 9  cost3.7224\n",
      "Epoch : 10  cost2.8256\n",
      "Epoch : 11  cost2.1011\n",
      "Epoch : 12  cost1.5685\n",
      "Epoch : 13  cost1.2556\n",
      "Epoch : 14  cost1.0443\n",
      "Epoch : 15  cost0.7974\n",
      "Model has completed 15 Epochs of training\n"
     ]
    }
   ],
   "source": [
    "# train the model for 15 epochs / loops\n",
    "\n",
    "for epoch in range(training_epochs):\n",
    "    \n",
    "    # Cost : starting value\n",
    "    avg_cost = 0.0\n",
    "    \n",
    "    total_batch = int(n_samples / batch_size)\n",
    "    \n",
    "    for i in range(total_batch):\n",
    "        \n",
    "        # grab the next batch of data and training labels using the next_batch convenience function\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        \n",
    "        # use the feed_dict for the optimization and loss value\n",
    "        # note; _ at beg of line denotes you do not need a value there during tuple unpacking situation\n",
    "        # returns the 'loss', which is the c value\n",
    "        _, c = sess.run([optimizer, cost], feed_dict={x:batch_x, y:batch_y})\n",
    "        \n",
    "        # \n",
    "        avg_cost += c / total_batch\n",
    "    \n",
    "    # print which epoch we are in\n",
    "    print(\"Epoch : {}  cost{:.4f}\".format(epoch+1, avg_cost))\n",
    "    \n",
    "print(\"Model has completed {} Epochs of training\".format(training_epochs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# evaluate the model using built-in tensorflow tools\n",
    "\n",
    "correct_predictions = tf.equal(tf.argmax(pred,1), tf.argmax(y,1))   # find outputs where pred = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"strided_slice:0\", shape=(), dtype=bool)\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "\n",
    "print(correct_predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cast tensor objects (booleans) into floats so we can average\n",
    "correct_predictions = tf.cast(correct_predictions, 'float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"strided_slice_1:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(correct_predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use tf.reduce_mean function to grab the mean of the elements across the tensor\n",
    "\n",
    "accuracy = tf.reduce_mean(correct_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.framework.ops.Tensor"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now we need to pass in the actual test data\n",
    "\n",
    "# call mnist test labes and images and evaluate our accuracy\n",
    "\n",
    "mnist.test.labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.32941177,  0.72549021,  0.62352943,\n",
       "        0.59215689,  0.23529413,  0.14117648,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.8705883 ,  0.99607849,  0.99607849,  0.99607849,  0.99607849,\n",
       "        0.9450981 ,  0.77647066,  0.77647066,  0.77647066,  0.77647066,\n",
       "        0.77647066,  0.77647066,  0.77647066,  0.77647066,  0.66666669,\n",
       "        0.20392159,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.26274511,  0.44705886,\n",
       "        0.28235295,  0.44705886,  0.63921571,  0.89019614,  0.99607849,\n",
       "        0.88235301,  0.99607849,  0.99607849,  0.99607849,  0.98039222,\n",
       "        0.89803928,  0.99607849,  0.99607849,  0.54901963,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.06666667,  0.25882354,  0.05490196,  0.26274511,\n",
       "        0.26274511,  0.26274511,  0.23137257,  0.08235294,  0.92549026,\n",
       "        0.99607849,  0.41568631,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.32549021,  0.99215692,  0.81960791,  0.07058824,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.08627451,  0.91372555,\n",
       "        1.        ,  0.32549021,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.50588238,  0.99607849,  0.9333334 ,  0.17254902,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.23137257,  0.97647065,\n",
       "        0.99607849,  0.24313727,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.52156866,  0.99607849,  0.73333335,  0.01960784,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.03529412,  0.80392164,\n",
       "        0.97254908,  0.227451  ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.49411768,  0.99607849,  0.71372551,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.29411766,  0.98431379,\n",
       "        0.94117653,  0.22352943,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.07450981,  0.86666673,  0.99607849,  0.65098041,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.01176471,  0.7960785 ,  0.99607849,\n",
       "        0.8588236 ,  0.13725491,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.14901961,  0.99607849,  0.99607849,  0.3019608 ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.12156864,  0.87843144,  0.99607849,\n",
       "        0.45098042,  0.00392157,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.52156866,  0.99607849,  0.99607849,  0.20392159,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.2392157 ,  0.94901967,  0.99607849,\n",
       "        0.99607849,  0.20392159,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.47450984,  0.99607849,  0.99607849,  0.8588236 ,  0.15686275,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.47450984,  0.99607849,\n",
       "        0.81176478,  0.07058824,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ], dtype=float32)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.test.images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94599998"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# eval method will allow you to directly evaluate the tensor in the session with having to call tf.sess.run\n",
    "\n",
    "accuracy.eval({x:mnist.test.images, y:mnist.test.labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# good, but is possible to get up to 99% by increasing number of epochs up to 1,000 - 10,000"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
