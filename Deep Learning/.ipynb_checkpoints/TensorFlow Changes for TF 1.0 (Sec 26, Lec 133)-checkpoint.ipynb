{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Changes with TensorFlow\n",
    "#Section 26, Lecture 133\n",
    "\n",
    "Hi everyone,\n",
    "\n",
    "TensorFlow changes very quickly with updates sometimes causing deprecated code for older versions. At this time of writing, the most recent release of TF is 1.0. In order to have your code work with 1.0\n",
    "\n",
    "Another change is that TF can now be downloaded directly for Windows (at least for CPU use, there are some caveats for GPU on Windows with TF). You can get the easier installation directions here:\n",
    "\n",
    "https://www.tensorflow.org/install/\n",
    "\n",
    "For the mnist section, here is the updated code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    " \n",
    "import tensorflow as tf\n",
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    " \n",
    "W = tf.Variable(tf.zeros([784, 10]))\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    " \n",
    "y = tf.nn.softmax(tf.matmul(x, W) + b)\n",
    " \n",
    "y_ = tf.placeholder(tf.float32, [None, 10])\n",
    " \n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1]))\n",
    " \n",
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\n",
    " \n",
    "sess = tf.InteractiveSession()\n",
    " \n",
    "tf.global_variables_initializer().run()\n",
    " \n",
    "for _ in range(1000):\n",
    "  batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "  sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})\n",
    " \n",
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    " \n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    " \n",
    "print(sess.run(accuracy, feed_dict={x: mnist.test.images, y_: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As far as the updated code, here is the most recent working code for the contrib.learn section that uses the iris dataset: (The main difference between this and the video is the addition of the feature_columns argument)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn import metrics\n",
    "import tensorflow as tf\n",
    " \n",
    " \n",
    "  # Load dataset.\n",
    "  iris = tf.contrib.learn.datasets.load_dataset('iris')\n",
    " \n",
    "  x_train, x_test, y_train, y_test = model_selection.train_test_split(\n",
    "      iris.data, iris.target, test_size=0.2, random_state=42)\n",
    " \n",
    "  # Build 3 layer DNN with 10, 20, 10 units respectively.\n",
    " \n",
    "  feature_columns = tf.contrib.learn.infer_real_valued_columns_from_input(\n",
    "      x_train)\n",
    " \n",
    "  classifier = tf.contrib.learn.DNNClassifier(\n",
    "      feature_columns=feature_columns, hidden_units=[10, 20, 10], n_classes=3)\n",
    " \n",
    "  # Fit and predict.\n",
    "  classifier.fit(x_train, y_train, steps=200)\n",
    "  predictions = list(classifier.predict(x_test, as_iterable=True))\n",
    "  score = metrics.accuracy_score(y_test, predictions)\n",
    "  print('Accuracy: {0:f}'.format(score))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
